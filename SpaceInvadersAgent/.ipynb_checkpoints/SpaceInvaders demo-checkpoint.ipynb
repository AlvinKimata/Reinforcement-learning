{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4827646-c39f-47a6-ab2c-909e9eaa4515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88885765-2670-47d9-b61b-3114b8216f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14af90e-f001-4c5c-aad8-5b6e9b50d347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space #6 possible actions to take in this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74440c6-9f3b-497b-bf3a-dbdbfdd1b982",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, reward: 155.0\n",
      "Episode: 2, reward: 50.0\n",
      "Episode: 3, reward: 110.0\n",
      "Episode: 4, reward: 45.0\n",
      "Episode: 5, reward: 65.0\n",
      "Episode: 6, reward: 210.0\n",
      "Episode: 7, reward: 125.0\n",
      "Episode: 8, reward: 150.0\n",
      "Episode: 9, reward: 155.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes):\n",
    "    state = env.reset() #Reset environment to initial state\n",
    "    done = False \n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        \n",
    "        #Add reward to score.\n",
    "        score += reward\n",
    "        \n",
    "    print(f'Episode: {episode}, reward: {score}')\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b6f00-a079-4dda-9884-993456841351",
   "metadata": {},
   "source": [
    "### _The agent is taking random actions. Implement a neural network where the agent learns intelligent behaviours based on the rewards that we give it, following reinforcement learning principles that humans follow._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674ef793-0030-406f-8975-7d856d917ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94fef8e0-f760-425c-a9f1-68e7de1c1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 14:55:42.341053: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 14:55:43.232299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debonair/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-14 14:55:43.232360: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-14 14:55:43.327627: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-14 14:55:45.541629: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debonair/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-14 14:55:45.541918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debonair/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-14 14:55:45.541950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ccefd1-e2fe-4f75-9ffa-f5de2afd761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channels, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (8, 8), strides = (4, 4), activation = 'relu', input_shape = (3, height, width, channels)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (4, 4), strides = (2, 2), activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(actions, activation = 'linear'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50af4f02-c796-4de0-b11c-507f3ccee074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d30e82-22ff-445a-8909-4969fcfd0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr = 'eps', value_max = 1., value_min = .1, \n",
    "                                  value_test = .2, nb_steps=1000)\n",
    "    \n",
    "    memory = SequentialMemory(limit = 2000, window_length = 3)\n",
    "    \n",
    "    dqn = DQNAgent(model = model, memory = memory, policy = policy, \n",
    "                   enable_dueling_network=True, dueling_type='avg',\n",
    "                   nb_actions = actions, nb_steps_warmup = 1000)\n",
    "    \n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1073a964-5bf5-41db-b1f4-91fa253378d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "model = build_model(height, width, channels, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d032cd0c-b9d1-465d-bdab-96463fd602da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f705ad1a-9d6e-447f-88bb-e9dd04379510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 14:57:16.471347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debonair/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-14 14:57:16.471482: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-14 14:57:16.471570: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debonair): /proc/driver/nvidia/version does not exist\n",
      "2022-11-14 14:57:16.472537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 14:57:16.579301: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "dqn.compile(Adam(learning_rate = 0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b84451ea-dfa8-4b53-8e2f-f9e8ae232da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 40000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 1114/10000 [==>...........................] - ETA: 16:48 - reward: 0.2783done, took 127.409 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb29e475580>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, \n",
    "        nb_steps = 40_000, #Same as epochs\n",
    "        visualize = False, #Visualize agent in environment when training.\n",
    "        verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9ec65-2c6c-4093-b788-379a30989775",
   "metadata": {},
   "source": [
    "### Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8fd7ab-cd92-4737-83a6-c3bbcf31ab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 380.000, steps: 853\n",
      "Episode 2: reward: 380.000, steps: 860\n",
      "Episode 3: reward: 355.000, steps: 861\n",
      "Episode 4: reward: 380.000, steps: 838\n",
      "Episode 5: reward: 380.000, steps: 853\n",
      "375.0\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes = 5, visualize = True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2fbbfb-b1a5-4d8b-ad4a-7cc4e36b6ac1",
   "metadata": {},
   "source": [
    "### Save and load model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6900738-e8af-424b-9996-67e328c262dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save weights.\n",
    "dqn.save_weights('models/dqn.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c96ac4be-616f-4a10-b4fc-e239232fbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model weights.\n",
    "dqn.load_weights('models/dqn.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e0389-39fa-4b71-b672-61b82cb60d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
